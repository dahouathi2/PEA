{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Train a scikit-learn model with Vertex AI SDK 2.0 and Bigframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This tutorial demonstrates how to train a scikit-learn model using Vertex AI local-to-remote training with Vertex AI SDK 2.0 and BigQuery Bigframes as the data source.\n",
        "\n",
        "Learn more about [bigframes](https://cloud.google.com/bigquery/docs/)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d975e698c9a4"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this tutorial, you learn to use `Vertex AI SDK 2.0` with Bigframes as input data source.\n",
        "\n",
        "\n",
        "This tutorial uses the following Google Cloud ML services:\n",
        "\n",
        "- `Vertex AI Training`\n",
        "- `Vertex AI Remote Training`\n",
        "\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Initialize a dataframe from a BigQuery table and split the dataset\n",
        "- Perform transformations as a Vertex AI remote training.\n",
        "- Train the model remotely and evaluate the model locally\n",
        "\n",
        "**Local-to-remote training**\n",
        "\n",
        "``` python\n",
        "import vertexai\n",
        "from my_module import MyModelClass\n",
        "\n",
        "vertexai.preview.init(remote=True, project=\"my-project\", location=\"my-location\", staging_bucket=\"gs://my-bucket\")\n",
        "\n",
        "# Wrap the model class with `vertex_ai.preview.remote`\n",
        "MyModelClass = vertexai.preview.remote(MyModelClass)\n",
        "\n",
        "# Instantiate the class\n",
        "model = MyModelClass(...)\n",
        "\n",
        "# Optional set remote config\n",
        "model.fit.vertex.remote_config.display_name = \"MyModelClass-remote-training\"\n",
        "model.fit.vertex.remote_config.staging_bucket = \"gs://my-bucket\"\n",
        "\n",
        "# This `fit` call will be executed remotely\n",
        "model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08d289fa873f"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This tutorial uses the <a href=\"https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\">IRIS dataset</a>, which predicts the iris species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aed92deeb4a0"
      },
      "source": [
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* BigQuery\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
        "[BigQuery pricing](https://cloud.google.com/bigquery/pricing),\n",
        "and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), \n",
        "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "- Follow the steps in [confluence](https://confluence.e-loreal.com/display/BTDPPAIML/2.2.1.0+Setup)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EUnXsZhAGF"
      },
      "source": [
        "## Installation\n",
        "\n",
        "(In case you do not use the pre installed kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2b4ef9b72d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 0.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.1.0 Requires-Python >=3.9; 0.1.1 Requires-Python >=3.9; 0.10.0 Requires-Python >=3.9; 0.11.0 Requires-Python >=3.9; 0.12.0 Requires-Python >=3.9; 0.13.0 Requires-Python >=3.9; 0.14.0 Requires-Python >=3.9; 0.14.1 Requires-Python >=3.9; 0.15.0 Requires-Python >=3.9; 0.16.0 Requires-Python >=3.9; 0.17.0 Requires-Python >=3.9; 0.18.0 Requires-Python >=3.9; 0.19.0 Requires-Python >=3.9; 0.19.1 Requires-Python >=3.9; 0.19.2 Requires-Python >=3.9; 0.2.0 Requires-Python >=3.9; 0.20.0 Requires-Python >=3.9; 0.20.1 Requires-Python >=3.9; 0.21.0 Requires-Python >=3.9; 0.22.0 Requires-Python >=3.9; 0.23.0 Requires-Python >=3.9; 0.24.0 Requires-Python >=3.9; 0.25.0 Requires-Python >=3.9; 0.26.0 Requires-Python >=3.9; 0.3.0 Requires-Python >=3.9; 0.4.0 Requires-Python >=3.9; 0.5.0 Requires-Python >=3.9; 0.6.0 Requires-Python >=3.9; 0.7.0 Requires-Python >=3.9; 0.8.0 Requires-Python >=3.9; 0.9.0 Requires-Python >=3.9; 1.0.0 Requires-Python >=3.9; 1.1.0 Requires-Python >=3.9; 1.2.0 Requires-Python >=3.9; 1.3.0 Requires-Python >=3.9; 1.4.0 Requires-Python >=3.9; 1.5.0 Requires-Python >=3.9; 1.6.0 Requires-Python >=3.9; 1.7.0 Requires-Python >=3.9\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement bigframes (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for bigframes\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the packages\n",
        "! pip3 install bigframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WReHDGG5g0XY"
      },
      "source": [
        "#### Set your project ID\n",
        "\n",
        "**If you don't know your project ID**, try the following:\n",
        "* Run `gcloud config list`.\n",
        "* Run `gcloud projects list`.\n",
        "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oM1iC_MfAts1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.config.set) argument VALUE: Must be specified.\n",
            "Usage: gcloud config set SECTION/PROPERTY VALUE [optional flags]\n",
            "  optional flags may be  --help | --installation\n",
            "\n",
            "For detailed information on this command and its flags, run:\n",
            "  gcloud config set --help\n"
          ]
        }
      ],
      "source": [
        "# Set the project id\n",
        "! gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "region"
      },
      "source": [
        "#### Region\n",
        "\n",
        "You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "region"
      },
      "outputs": [],
      "source": [
        "REGION = \"europe-west1\" "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sBCra4QMA2wR"
      },
      "source": [
        "### Authenticate your Google Cloud account\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "de775a3773ba"
      },
      "source": [
        "**Inside the workstation terminal, type following command:** </br>\n",
        "\n",
        "<code>! gcloud auth login</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "### Create a Cloud Storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://{PROJECT_ID}-big-frames-bucket\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NIq7R4HZCfIc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CommandException: The mb command requires at least 1 argument. Usage:\n",
            "\n",
            "  gsutil mb [-b (on|off)] [-c <class>] [-k <key>] [-l <location>] [-p <project>]\n",
            "            [--autoclass] [--retention <time>] [--pap <setting>]\n",
            "            [--placement <region1>,<region2>]\n",
            "            [--rpo (ASYNC_TURBO|DEFAULT)] gs://<bucket_name>...\n",
            "\n",
            "For additional help run:\n",
            "  gsutil help mb\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "960505627ddf"
      },
      "source": [
        "### Import libraries and define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PyQmSRbKA8r-"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import vertex_utils as vertex_utils\n",
        "\n",
        "REMOTE_JOB_NAME = \"sdk2-bigframes-sklearn\"\n",
        "REMOTE_JOB_BUCKET = f\"{BUCKET_URI}/{REMOTE_JOB_NAME}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "source": [
        "## Initialize Vertex AI SDK for Python\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_aip:mbsdk,all"
      },
      "outputs": [],
      "source": [
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=BUCKET_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vertex_helper = vertex_utils.VertexHelper(staging_bucket=BUCKET_URI, remote_job_name=REMOTE_JOB_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105334524e96"
      },
      "source": [
        "## Prepare the dataset\n",
        "\n",
        "Now load the Iris dataset and split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b44cdc4e03f1"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bf\n",
        "df = bf.read_gbq(\"bigquery-public-data.ml_datasets.iris\")\n",
        "\n",
        "species_categories = {\n",
        "    \"versicolor\": 0,\n",
        "    \"virginica\": 1,\n",
        "    \"setosa\": 2,\n",
        "}\n",
        "df[\"species\"] = df[\"species\"].map(species_categories)\n",
        "\n",
        "# Assign an index column name\n",
        "index_col = \"index\"\n",
        "df.index.name = index_col\n",
        "\n",
        "\n",
        "pdf = df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cb8616b1997"
      },
      "outputs": [],
      "source": [
        "feature_columns = df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
        "label_columns = df[[\"species\"]]\n",
        "train_X, test_X, train_y, test_y = bf_train_test_split(\n",
        "    feature_columns, label_columns, test_size=0.2\n",
        ")\n",
        "\n",
        "print(\"X_train size: \", train_X.size)\n",
        "print(\"X_test size: \", test_X.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8306545fcc57"
      },
      "source": [
        "## Feature transformation\n",
        "\n",
        "Next, you do feature transformations on the data using the Vertex AI remote training service.\n",
        "\n",
        "First, you re-initialize Vertex AI to enable remote training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55e701c31036"
      },
      "outputs": [],
      "source": [
        "# Switch to remote mode for training\n",
        "vertexai.preview.init(remote=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a0e9d59b273"
      },
      "source": [
        "### Execute remote job for fit_transform() on training data\n",
        "\n",
        "Next, indicate that the `StandardScalar` class is to be executed remotely. Then set up the data transform and call the `fit_transform()` method is executed remotely."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The vanilla way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90333089d362"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Wrap classes to enable Vertex remote execution\n",
        "StandardScaler = vertexai.preview.remote(StandardScaler)\n",
        "\n",
        "# Instantiate transformer\n",
        "transformer = StandardScaler()\n",
        "\n",
        "# Set training config\n",
        "transformer.fit_transform.vertex.remote_config.display_name = (\n",
        "    f\"{REMOTE_JOB_NAME}-fit-transformer-bigframes\"\n",
        ")\n",
        "transformer.fit_transform.vertex.remote_config.staging_bucket = REMOTE_JOB_BUCKET\n",
        "transformer.fit_transform.vertex.remote_config.machine_type = 'e2-standard-8'\n",
        "\n",
        "# Execute transformer on Vertex (train_X is bigframes.dataframe.DataFrame, X_train is np.array)\n",
        "X_train = transformer.fit_transform(train_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remote transform on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform test dataset before calculate test score\n",
        "transformer.transform.vertex.remote_config.display_name = (\n",
        "    REMOTE_JOB_NAME + \"-transformer\"\n",
        ")\n",
        "transformer.transform.vertex.remote_config.staging_bucket = REMOTE_JOB_BUCKET\n",
        "\n",
        "# Execute transformer on Vertex (test_X is bigframes.dataframe.DataFrame, X_test is np.array)\n",
        "X_test = transformer.transform(test_X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using vertex helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# wrap the model\n",
        "StandardScaler = vertex_helper.wrap_model(StandardScaler)\n",
        "\n",
        "# init as usual\n",
        "transformer = StandardScaler()\n",
        "\n",
        "# enables the remote on all the functions\n",
        "transformer = vertex_helper.enable_for_remote(transformer)\n",
        "\n",
        "X_train = transformer.fit_transform(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = transformer.transform(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddf906c886e4"
      },
      "source": [
        "## Remote training\n",
        "\n",
        "First, train the scikit-learn model as a remote training job:\n",
        "\n",
        "- Set LogisticRegression for the remote training job.\n",
        "- Invoke LogisticRegression locally which will launch the remote training job."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vanilla way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7b0116fa60c"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Wrap classes to enable Vertex remote execution\n",
        "LogisticRegression = vertexai.preview.remote(LogisticRegression)\n",
        "\n",
        "# Instantiate model, warm_start=True for uptraining\n",
        "model = LogisticRegression(warm_start=True)\n",
        "\n",
        "# Set training config\n",
        "model.fit.vertex.remote_config.display_name = REMOTE_JOB_NAME + \"-sklearn-model\"\n",
        "model.fit.vertex.remote_config.staging_bucket = REMOTE_JOB_BUCKET\n",
        "\n",
        "# Train model on Vertex, train_X, train_y are bigframes  \n",
        "model.fit(train_X, train_y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vertex helper way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# wrap the class\n",
        "LogisticRegression = vertex_helper.wrap_model(LogisticRegression)\n",
        "\n",
        "# instantiate as usual\n",
        "model = LogisticRegression(warm_start=True)\n",
        "\n",
        "# enable the instance for remote execution\n",
        "model = vertex_helper.enable_for_remote(model)\n",
        "\n",
        "# Train model on Vertex, train_X, train_y are bigframes  \n",
        "model.fit(train_X, train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffe1d5903bcb"
      },
      "source": [
        "## Remote prediction\n",
        "\n",
        "Obtain predictions from the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d00ce35920fa"
      },
      "outputs": [],
      "source": [
        "# Remote evaluation\n",
        "vertexai.preview.init(remote=True)\n",
        "\n",
        "# Evaluate model's accuracy score\n",
        "predictions = model.predict(test_X)\n",
        "\n",
        "print(f\"Remote predictions: {predictions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8cd6cbd4403"
      },
      "source": [
        "## Local evaluation\n",
        "\n",
        "Score model results locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc105dafdfb9"
      },
      "outputs": [],
      "source": [
        "# User must convert bigframes to pandas dataframe for local evaluation\n",
        "train_X_pd = train_X.to_pandas().reset_index(drop=True)\n",
        "train_y_pd = train_y.to_pandas().reset_index(drop=True)\n",
        "\n",
        "test_X_pd = test_X.to_pandas().reset_index(drop=True)\n",
        "test_y_pd = test_y.to_pandas().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25fec549de69"
      },
      "outputs": [],
      "source": [
        "# Switch to local mode for testing\n",
        "vertexai.preview.init(remote=False)\n",
        "\n",
        "# Evaluate model's accuracy score\n",
        "print(f\"Train accuracy: {model.score(train_X_pd, train_y_pd)}\")\n",
        "\n",
        "print(f\"Test accuracy: {model.score(test_X_pd, test_y_pd)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "\n",
        "Otherwise, you can delete the individual resources you created in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Delete Cloud Storage objects that were created\n",
        "delete_bucket = False\n",
        "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
        "    ! gsutil -m rm -r $BUCKET_URI"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sdk2_bigframes_sklearn.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
